{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1706.98it/s]\n",
      "d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run victorious-bird-318 at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0/runs/685e4935b5d544838f9f8ea44ae6740b\n",
      "ðŸ§ª View experiment at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from mlflow.models import infer_signature\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "dagshub_token = os.getenv(\"DAGSHUB_PAT\")\n",
    "if not dagshub_token:\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\n",
    "    \"https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_vectorizer(vectorizer_path: str) -> TfidfVectorizer:\n",
    "    with open(vectorizer_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_params(params_path: str) -> dict:\n",
    "    with open(params_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test: np.ndarray, y_test: np.ndarray):\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return report, cm\n",
    "\n",
    "\n",
    "def log_confusion_matrix(cm, dataset_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {dataset_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    cm_file_path = f'confusion_matrix_{dataset_name}.png'\n",
    "    plt.savefig(cm_file_path)\n",
    "    mlflow.log_artifact(local_path=cm_file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_model_info(run_id: str, model_path: str, file_path: str) -> None:\n",
    "    model_info = {\n",
    "        \"run_id\": run_id,\n",
    "        \"model_path\": model_path\n",
    "    }\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(model_info, file, indent=4)\n",
    "\n",
    "#mlflow.lightgbm.autolog(log_input_examples=True)\n",
    "\n",
    "# Load params\n",
    "root_dir = r\"D:\\yt-comment-sentiment-analysis2\\notebooks\"\n",
    "params = load_params(os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\params.yaml\"))\n",
    "# Load test data\n",
    "test_data = load_data(\n",
    "    os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2/data/interim/test_processed.csv\")\n",
    ")\n",
    "dataset = mlflow.data.from_pandas(test_data, name=\"evaluation_set\")\n",
    "\n",
    "def main():\n",
    "    mlflow.set_experiment(\"dvc-pipeline-1\")\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        \n",
    "\n",
    "        # Log parameters\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "        # Load model and vectorizer\n",
    "        model = load_model(os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\lgbm_model.pkl\"))\n",
    "        vectorizer = load_vectorizer(os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\"))\n",
    "\n",
    "        \n",
    "\n",
    "        X_test_tfidf = vectorizer.transform(test_data[\"clean_comment\"].values)\n",
    "\n",
    "        X_test_df = pd.DataFrame(\n",
    "            X_test_tfidf.toarray(),\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "        y_test = test_data[\"category\"].values\n",
    "\n",
    "        # Signature inference\n",
    "        input_example = pd.DataFrame(\n",
    "            X_test_tfidf.toarray()[:5],\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        signature = infer_signature(\n",
    "            X_test_df[:5],\n",
    "            model.predict(X_test_df[:5])\n",
    "        )\n",
    "\n",
    "        # Log model\n",
    "        mlflow.lightgbm.log_model(\n",
    "            model,\n",
    "            name = \"lgbm_model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "        # Save model info\n",
    "        save_model_info(run.info.run_id, \"lgbm_model\", \"experiment_info.json\")\n",
    "\n",
    "        # Log vectorizer\n",
    "        mlflow.log_artifact(local_path=os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\"))\n",
    "\n",
    "        #log data\n",
    "        mlflow.log_input(dataset , context=\"evaluation\")\n",
    "        \n",
    "        # Evaluate\n",
    "        report, cm = evaluate_model(model, X_test_df, y_test)\n",
    "\n",
    "        # Log metrics\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                mlflow.log_metrics({\n",
    "                    f\"test_{label}_precision\": metrics[\"precision\"],\n",
    "                    f\"test_{label}_recall\": metrics[\"recall\"],\n",
    "                    f\"test_{label}_f1-score\": metrics[\"f1-score\"]\n",
    "                })\n",
    "\n",
    "        # Log confusion matrix\n",
    "        log_confusion_matrix(cm, \"Test Data\")\n",
    "\n",
    "        # Tags\n",
    "        mlflow.set_tag(\"model_type\", \"LightGBM\")\n",
    "        mlflow.set_tag(\"task\", \"Sentiment Analysis\")\n",
    "        mlflow.set_tag(\"dataset\", \"YouTube Comments\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b802fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad5c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 11:43:57,926 - INFO - Loading params from D:\\yt-comment-sentiment-analysis2\\params.yaml\n",
      "2026-01-28 11:43:57,927 - INFO - Loading data from D:\\yt-comment-sentiment-analysis2\\data\\interim\\test_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 11:43:57,952 - INFO - Starting MLflow evaluation run\n",
      "2026-01-28 11:43:59,425 - INFO - MLflow run started: 5bb93147e62b4ba894a71e47c57ed7dc\n",
      "2026-01-28 11:44:00,111 - INFO - Loading model from D:\\yt-comment-sentiment-analysis2\\lgbm_model.pkl\n",
      "2026-01-28 11:44:00,124 - INFO - Loading vectorizer from D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1404.05it/s]\n",
      "2026-01-28 11:44:30,029 - INFO - Saving model info\n",
      "d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2026-01-28 11:44:31,573 - INFO - Evaluating model\n",
      "2026-01-28 11:44:33,585 - INFO - Logging confusion matrix\n",
      "2026-01-28 11:44:35,135 - INFO - Model evaluation completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run auspicious-doe-331 at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0/runs/5bb93147e62b4ba894a71e47c57ed7dc\n",
      "ðŸ§ª View experiment at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from mlflow.models import infer_signature\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "import logging   # ðŸ”´ added\n",
    "\n",
    "# -------------------- LOGGING SETUP --------------------\n",
    "logger = logging.getLogger(\"model_evaluation\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "if not logger.handlers:\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    file_handler = logging.FileHandler(\"model_evaluation.log\")\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    console_handler.setFormatter(formatter)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "dagshub_token = os.getenv(\"DAGSHUB_PAT\")\n",
    "if not dagshub_token:\n",
    "    logger.error(\"DAGSHUB_PAT environment variable is not set\")\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "mlflow.set_tracking_uri(\n",
    "    \"https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    logger.info(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('', inplace=True)\n",
    "    logger.debug(f\"Data shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    logger.info(f\"Loading model from {model_path}\")\n",
    "    with open(model_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_vectorizer(vectorizer_path: str) -> TfidfVectorizer:\n",
    "    logger.info(f\"Loading vectorizer from {vectorizer_path}\")\n",
    "    with open(vectorizer_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_params(params_path: str) -> dict:\n",
    "    logger.info(f\"Loading params from {params_path}\")\n",
    "    with open(params_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test: pd.DataFrame, y_test: np.ndarray):\n",
    "    logger.info(\"Evaluating model\")\n",
    "    logger.debug(f\"X_test shape: {X_test.shape}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return report, cm\n",
    "\n",
    "\n",
    "def log_confusion_matrix(cm, dataset_name):\n",
    "    logger.info(\"Logging confusion matrix\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {dataset_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    cm_file_path = f'confusion_matrix_{dataset_name}.png'\n",
    "    plt.savefig(cm_file_path)\n",
    "    mlflow.log_artifact(local_path=cm_file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_model_info(run_id: str, model_path: str, file_path: str) -> None:\n",
    "    logger.info(\"Saving model info\")\n",
    "    model_info = {\n",
    "        \"run_id\": run_id,\n",
    "        \"model_path\": model_path\n",
    "    }\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(model_info, file, indent=4)\n",
    "\n",
    "\n",
    "# -------------------- LOAD STATIC DATA --------------------\n",
    "root_dir = r\"D:\\yt-comment-sentiment-analysis2\\notebooks\"\n",
    "\n",
    "params = load_params(\n",
    "    os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\params.yaml\")\n",
    ")\n",
    "\n",
    "test_data = load_data(\n",
    "    os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\data\\interim\\test_processed.csv\")\n",
    ")\n",
    "\n",
    "dataset = mlflow.data.from_pandas(test_data, name=\"evaluation_set\")\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Starting MLflow evaluation run\")\n",
    "    mlflow.set_experiment(\"dvc-pipeline-1\")\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        logger.info(f\"MLflow run started: {run.info.run_id}\")\n",
    "\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "        model = load_model(\n",
    "            os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\lgbm_model.pkl\")\n",
    "        )\n",
    "        vectorizer = load_vectorizer(\n",
    "            os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\")\n",
    "        )\n",
    "\n",
    "        X_test_tfidf = vectorizer.transform(test_data[\"clean_comment\"].values)\n",
    "\n",
    "        X_test_df = pd.DataFrame(\n",
    "            X_test_tfidf.toarray(),\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        y_test = test_data[\"category\"].values\n",
    "\n",
    "        input_example = X_test_df[:5].astype(\"float32\")\n",
    "\n",
    "        signature = infer_signature(\n",
    "            input_example,\n",
    "            model.predict(input_example)\n",
    "        )\n",
    "\n",
    "        mlflow.lightgbm.log_model(\n",
    "            model,\n",
    "            name=\"lgbm_model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "        save_model_info(run.info.run_id, \"lgbm_model\", \"experiment_info.json\")\n",
    "\n",
    "        mlflow.log_artifact(\n",
    "            local_path=os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\")\n",
    "        )\n",
    "\n",
    "        mlflow.log_input(dataset, context=\"evaluation\")\n",
    "\n",
    "        report, cm = evaluate_model(model, X_test_df, y_test)\n",
    "\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                mlflow.log_metrics({\n",
    "                    f\"test_{label}_precision\": metrics[\"precision\"],\n",
    "                    f\"test_{label}_recall\": metrics[\"recall\"],\n",
    "                    f\"test_{label}_f1-score\": metrics[\"f1-score\"]\n",
    "                })\n",
    "\n",
    "        log_confusion_matrix(cm, \"Test Data\")\n",
    "\n",
    "        mlflow.set_tag(\"model_type\", \"LightGBM\")\n",
    "        mlflow.set_tag(\"task\", \"Sentiment Analysis\")\n",
    "        mlflow.set_tag(\"dataset\", \"YouTube Comments\")\n",
    "\n",
    "        logger.info(\"Model evaluation completed successfully\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
