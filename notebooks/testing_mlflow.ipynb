{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a8a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1706.98it/s]\n",
      "d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run victorious-bird-318 at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0/runs/685e4935b5d544838f9f8ea44ae6740b\n",
      "ðŸ§ª View experiment at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from mlflow.models import infer_signature\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "dagshub_token = os.getenv(\"DAGSHUB_PAT\")\n",
    "if not dagshub_token:\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "# Set up MLflow tracking URI\n",
    "mlflow.set_tracking_uri(\n",
    "    \"https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_vectorizer(vectorizer_path: str) -> TfidfVectorizer:\n",
    "    with open(vectorizer_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_params(params_path: str) -> dict:\n",
    "    with open(params_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test: np.ndarray, y_test: np.ndarray):\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return report, cm\n",
    "\n",
    "\n",
    "def log_confusion_matrix(cm, dataset_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {dataset_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    cm_file_path = f'confusion_matrix_{dataset_name}.png'\n",
    "    plt.savefig(cm_file_path)\n",
    "    mlflow.log_artifact(local_path=cm_file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_model_info(run_id: str, model_path: str, file_path: str) -> None:\n",
    "    model_info = {\n",
    "        \"run_id\": run_id,\n",
    "        \"model_path\": model_path\n",
    "    }\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(model_info, file, indent=4)\n",
    "\n",
    "#mlflow.lightgbm.autolog(log_input_examples=True)\n",
    "\n",
    "# Load params\n",
    "root_dir = r\"D:\\yt-comment-sentiment-analysis2\\notebooks\"\n",
    "params = load_params(os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\params.yaml\"))\n",
    "# Load test data\n",
    "test_data = load_data(\n",
    "    os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2/data/interim/test_processed.csv\")\n",
    ")\n",
    "dataset = mlflow.data.from_pandas(test_data, name=\"evaluation_set\")\n",
    "\n",
    "def main():\n",
    "    mlflow.set_experiment(\"dvc-pipeline-1\")\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        \n",
    "\n",
    "        # Log parameters\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "        # Load model and vectorizer\n",
    "        model = load_model(os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\lgbm_model.pkl\"))\n",
    "        vectorizer = load_vectorizer(os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\"))\n",
    "\n",
    "        \n",
    "\n",
    "        X_test_tfidf = vectorizer.transform(test_data[\"clean_comment\"].values)\n",
    "\n",
    "        X_test_df = pd.DataFrame(\n",
    "            X_test_tfidf.toarray(),\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "        y_test = test_data[\"category\"].values\n",
    "\n",
    "        # Signature inference\n",
    "        input_example = pd.DataFrame(\n",
    "            X_test_tfidf.toarray()[:5],\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        signature = infer_signature(\n",
    "            X_test_df[:5],\n",
    "            model.predict(X_test_df[:5])\n",
    "        )\n",
    "\n",
    "        # Log model\n",
    "        mlflow.lightgbm.log_model(\n",
    "            model,\n",
    "            name = \"lgbm_model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example,\n",
    "            registered_model_name=\"light_gbm_v1\",\n",
    "        \n",
    "        )\n",
    "\n",
    "        # Save model info\n",
    "        save_model_info(run.info.run_id, \"lgbm_model\", \"experiment_info.json\")\n",
    "\n",
    "        # Log vectorizer\n",
    "        mlflow.log_artifact(local_path=os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\"))\n",
    "\n",
    "        #log data\n",
    "        mlflow.log_input(dataset , context=\"evaluation\")\n",
    "        \n",
    "        # Evaluate\n",
    "        report, cm = evaluate_model(model, X_test_df, y_test)\n",
    "\n",
    "        # Log metrics\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                mlflow.log_metrics({\n",
    "                    f\"test_{label}_precision\": metrics[\"precision\"],\n",
    "                    f\"test_{label}_recall\": metrics[\"recall\"],\n",
    "                    f\"test_{label}_f1-score\": metrics[\"f1-score\"]\n",
    "                })\n",
    "\n",
    "        # Log confusion matrix\n",
    "        log_confusion_matrix(cm, \"Test Data\")\n",
    "\n",
    "        # Tags\n",
    "        mlflow.set_tag(\"model_type\", \"LightGBM\")\n",
    "        mlflow.set_tag(\"task\", \"Sentiment Analysis\")\n",
    "        mlflow.set_tag(\"dataset\", \"YouTube Comments\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b802fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ad5c984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 11:43:57,926 - INFO - Loading params from D:\\yt-comment-sentiment-analysis2\\params.yaml\n",
      "2026-01-28 11:43:57,927 - INFO - Loading data from D:\\yt-comment-sentiment-analysis2\\data\\interim\\test_processed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-28 11:43:57,952 - INFO - Starting MLflow evaluation run\n",
      "2026-01-28 11:43:59,425 - INFO - MLflow run started: 5bb93147e62b4ba894a71e47c57ed7dc\n",
      "2026-01-28 11:44:00,111 - INFO - Loading model from D:\\yt-comment-sentiment-analysis2\\lgbm_model.pkl\n",
      "2026-01-28 11:44:00,124 - INFO - Loading vectorizer from D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\n",
      "Downloading artifacts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 1404.05it/s]\n",
      "2026-01-28 11:44:30,029 - INFO - Saving model info\n",
      "d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\types\\utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2026-01-28 11:44:31,573 - INFO - Evaluating model\n",
      "2026-01-28 11:44:33,585 - INFO - Logging confusion matrix\n",
      "2026-01-28 11:44:35,135 - INFO - Model evaluation completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run auspicious-doe-331 at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0/runs/5bb93147e62b4ba894a71e47c57ed7dc\n",
      "ðŸ§ª View experiment at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import yaml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "from mlflow.models import infer_signature\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "import logging   # ðŸ”´ added\n",
    "\n",
    "# -------------------- LOGGING SETUP --------------------\n",
    "logger = logging.getLogger(\"model_evaluation\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "if not logger.handlers:\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "\n",
    "    file_handler = logging.FileHandler(\"model_evaluation.log\")\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "    formatter = logging.Formatter(\n",
    "        \"%(asctime)s - %(levelname)s - %(message)s\"\n",
    "    )\n",
    "    console_handler.setFormatter(formatter)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "dagshub_token = os.getenv(\"DAGSHUB_PAT\")\n",
    "if not dagshub_token:\n",
    "    logger.error(\"DAGSHUB_PAT environment variable is not set\")\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "mlflow.set_tracking_uri(\n",
    "    \"https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow\"\n",
    ")\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    logger.info(f\"Loading data from {file_path}\")\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('', inplace=True)\n",
    "    logger.debug(f\"Data shape: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_model(model_path: str):\n",
    "    logger.info(f\"Loading model from {model_path}\")\n",
    "    with open(model_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_vectorizer(vectorizer_path: str) -> TfidfVectorizer:\n",
    "    logger.info(f\"Loading vectorizer from {vectorizer_path}\")\n",
    "    with open(vectorizer_path, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "\n",
    "def load_params(params_path: str) -> dict:\n",
    "    logger.info(f\"Loading params from {params_path}\")\n",
    "    with open(params_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test: pd.DataFrame, y_test: np.ndarray):\n",
    "    logger.info(\"Evaluating model\")\n",
    "    logger.debug(f\"X_test shape: {X_test.shape}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    return report, cm\n",
    "\n",
    "\n",
    "def log_confusion_matrix(cm, dataset_name):\n",
    "    logger.info(\"Logging confusion matrix\")\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix for {dataset_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "\n",
    "    cm_file_path = f'confusion_matrix_{dataset_name}.png'\n",
    "    plt.savefig(cm_file_path)\n",
    "    mlflow.log_artifact(local_path=cm_file_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_model_info(run_id: str, model_path: str, file_path: str) -> None:\n",
    "    logger.info(\"Saving model info\")\n",
    "    model_info = {\n",
    "        \"run_id\": run_id,\n",
    "        \"model_path\": model_path\n",
    "    }\n",
    "    with open(file_path, \"w\") as file:\n",
    "        json.dump(model_info, file, indent=4)\n",
    "\n",
    "\n",
    "# -------------------- LOAD STATIC DATA --------------------\n",
    "root_dir = r\"D:\\yt-comment-sentiment-analysis2\\notebooks\"\n",
    "\n",
    "params = load_params(\n",
    "    os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\params.yaml\")\n",
    ")\n",
    "\n",
    "test_data = load_data(\n",
    "    os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\data\\interim\\test_processed.csv\")\n",
    ")\n",
    "\n",
    "dataset = mlflow.data.from_pandas(test_data, name=\"evaluation_set\")\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\n",
    "def main():\n",
    "    logger.info(\"Starting MLflow evaluation run\")\n",
    "    mlflow.set_experiment(\"dvc-pipeline-1\")\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "        logger.info(f\"MLflow run started: {run.info.run_id}\")\n",
    "\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "\n",
    "        model = load_model(\n",
    "            os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\lgbm_model.pkl\")\n",
    "        )\n",
    "        vectorizer = load_vectorizer(\n",
    "            os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\")\n",
    "        )\n",
    "\n",
    "        X_test_tfidf = vectorizer.transform(test_data[\"clean_comment\"].values)\n",
    "\n",
    "        X_test_df = pd.DataFrame(\n",
    "            X_test_tfidf.toarray(),\n",
    "            columns=vectorizer.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        y_test = test_data[\"category\"].values\n",
    "\n",
    "        input_example = X_test_df[:5].astype(\"float32\")\n",
    "\n",
    "        signature = infer_signature(\n",
    "            input_example,\n",
    "            model.predict(input_example)\n",
    "        )\n",
    "\n",
    "        mlflow.lightgbm.log_model(\n",
    "            model,\n",
    "            name=\"lgbm_model\",\n",
    "            signature=signature,\n",
    "            input_example=input_example\n",
    "        )\n",
    "\n",
    "        save_model_info(run.info.run_id, \"lgbm_model\", \"experiment_info.json\")\n",
    "\n",
    "        mlflow.log_artifact(\n",
    "            local_path=os.path.join(root_dir, r\"D:\\yt-comment-sentiment-analysis2\\tfidf_vectorizer.pkl\")\n",
    "        )\n",
    "\n",
    "        mlflow.log_input(dataset, context=\"evaluation\")\n",
    "\n",
    "        report, cm = evaluate_model(model, X_test_df, y_test)\n",
    "\n",
    "        for label, metrics in report.items():\n",
    "            if isinstance(metrics, dict):\n",
    "                mlflow.log_metrics({\n",
    "                    f\"test_{label}_precision\": metrics[\"precision\"],\n",
    "                    f\"test_{label}_recall\": metrics[\"recall\"],\n",
    "                    f\"test_{label}_f1-score\": metrics[\"f1-score\"]\n",
    "                })\n",
    "\n",
    "        log_confusion_matrix(cm, \"Test Data\")\n",
    "\n",
    "        mlflow.set_tag(\"model_type\", \"LightGBM\")\n",
    "        mlflow.set_tag(\"task\", \"Sentiment Analysis\")\n",
    "        mlflow.set_tag(\"dataset\", \"YouTube Comments\")\n",
    "\n",
    "        logger.info(\"Model evaluation completed successfully\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e084c3a",
   "metadata": {},
   "source": [
    "# testing_mlflow autolog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575d43f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 12:13:45,068 - model_building - DEBUG - TF-IDF shape: (27226, 10000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 121145\n",
      "[LightGBM] [Info] Number of data points in the train set: 27226, number of used features: 4127\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Info] Start training from score -1.098612\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "ðŸƒ View run persistent-ox-231 at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0/runs/ac234ef83c64425bb6c44dd984372769\n",
      "ðŸ§ª View experiment at: https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow/#/experiments/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-29 12:15:55,109 - model_building - ERROR - Model building pipeline failed\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_29068\\3206956612.py\", line 141, in main\n",
      "    model = train_lgbm(\n",
      "            ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_29068\\3206956612.py\", line 104, in train_lgbm\n",
      "    mlflow.pyfunc.log_model(\n",
      "  File \"d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\tracing\\provider.py\", line 633, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 3600, in log_model\n",
      "    return Model.log(\n",
      "           ^^^^^^^^^^\n",
      "  File \"d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\models\\model.py\", line 1209, in log\n",
      "    flavor.save_model(path=local_path, mlflow_model=mlflow_model, **kwargs)\n",
      "  File \"d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\tracing\\provider.py\", line 638, in wrapper\n",
      "    result = f(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 3059, in save_model\n",
      "    _validate_function_python_model(python_model)\n",
      "  File \"d:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py\", line 2823, in _validate_function_python_model\n",
      "    raise MlflowException(\n",
      "mlflow.exceptions.MlflowException: `python_model` must be a PythonModel instance, callable object, or path to a script that uses set_model() to set a PythonModel instance or callable object.\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "`python_model` must be a PythonModel instance, callable object, or path to a script that uses set_model() to set a PythonModel instance or callable object.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 165\u001b[39m\n\u001b[32m    161\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 141\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    126\u001b[39m train_data = load_data(\n\u001b[32m    127\u001b[39m     os.path.join(\n\u001b[32m    128\u001b[39m         ROOT_DIR,\n\u001b[32m   (...)\u001b[39m\u001b[32m    132\u001b[39m     )\n\u001b[32m    133\u001b[39m )\n\u001b[32m    135\u001b[39m X_train_tfidf, y_train = apply_tfidf(\n\u001b[32m    136\u001b[39m     train_data,\n\u001b[32m    137\u001b[39m     mb_params[\u001b[33m\"\u001b[39m\u001b[33mmax_features\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    138\u001b[39m     \u001b[38;5;28mtuple\u001b[39m(mb_params[\u001b[33m\"\u001b[39m\u001b[33mngram_range\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    139\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m model = \u001b[43mtrain_lgbm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmb_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlearning_rate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmb_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_depth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmb_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn_estimators\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m save_model(\n\u001b[32m    150\u001b[39m     model,\n\u001b[32m    151\u001b[39m     os.path.join(ROOT_DIR, \u001b[33m\"\u001b[39m\u001b[33mlgbm_model.pkl\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    152\u001b[39m )\n\u001b[32m    154\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mModel training completed successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mtrain_lgbm\u001b[39m\u001b[34m(X_train, y_train, learning_rate, max_depth, n_estimators)\u001b[39m\n\u001b[32m    101\u001b[39m     model.fit(X_train, y_train)\n\u001b[32m    103\u001b[39m     \u001b[38;5;66;03m# ðŸ”´ THIS LINE IS MANDATORY\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# MLflow 3.x\u001b[39;49;00m\n\u001b[32m    107\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\tracing\\provider.py:633\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m     is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    635\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:3600\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001b[39m\n\u001b[32m   3400\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3401\u001b[39m \u001b[33;03mLog a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[32m   3402\u001b[39m \u001b[33;03martifact for the current run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3597\u001b[39m \u001b[33;03m    metadata of the logged model.\u001b[39;00m\n\u001b[32m   3598\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3599\u001b[39m flavor_name = _get_pyfunc_model_flavor_name(python_model)\n\u001b[32m-> \u001b[39m\u001b[32m3600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3601\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3621\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3628\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only used for checking python model type\u001b[39;49;00m\n\u001b[32m   3629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3630\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\models\\model.py:1209\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[39m\n\u001b[32m   1197\u001b[39m     prompts = [pr.uri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, PromptVersion) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m   1199\u001b[39m mlflow_model = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m   1200\u001b[39m     artifact_path=model.artifact_location,\n\u001b[32m   1201\u001b[39m     model_uuid=model.model_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m     model_id=model.model_id,\n\u001b[32m   1208\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[43mflavor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001b[39;00m\n\u001b[32m   1211\u001b[39m \u001b[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path).rglob(\u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\tracing\\provider.py:638\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    637\u001b[39m         is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m         result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:3059\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(path, loader_module, data_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, **kwargs)\u001b[39m\n\u001b[32m   3056\u001b[39m     _validate_and_copy_file_to_directory(model_code_path, path, \u001b[33m\"\u001b[39m\u001b[33mcode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3057\u001b[39m     python_model = _load_model_code_path(model_code_path, model_config)\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m \u001b[43m_validate_function_python_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3060\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(python_model) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   3061\u001b[39m     a \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m (input_example, pip_requirements, extra_pip_requirements)\n\u001b[32m   3062\u001b[39m ):\n\u001b[32m   3063\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   3064\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf `python_model` is a callable object, at least one of `input_example`, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3065\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`pip_requirements`, or `extra_pip_requirements` must be specified.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   3066\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\yt-comment-sentiment-analysis2\\myenv\\Lib\\site-packages\\mlflow\\pyfunc\\__init__.py:2823\u001b[39m, in \u001b[36m_validate_function_python_model\u001b[39m\u001b[34m(python_model)\u001b[39m\n\u001b[32m   2821\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_function_python_model\u001b[39m(python_model):\n\u001b[32m   2822\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(python_model, PythonModel) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(python_model)):\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   2824\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`python_model` must be a PythonModel instance, callable object, or path to a script \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2825\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthat uses set_model() to set a PythonModel instance or callable object.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2826\u001b[39m             error_code=INVALID_PARAMETER_VALUE,\n\u001b[32m   2827\u001b[39m         )\n\u001b[32m   2829\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(python_model):\n\u001b[32m   2830\u001b[39m         num_args = \u001b[38;5;28mlen\u001b[39m(inspect.signature(python_model).parameters)\n",
      "\u001b[31mMlflowException\u001b[39m: `python_model` must be a PythonModel instance, callable object, or path to a script that uses set_model() to set a PythonModel instance or callable object."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "import logging\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import mlflow\n",
    "import dagshub\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "# Set up DagsHub credentials for MLflow tracking\n",
    "dagshub_token = os.getenv(\"DAGSHUB_PAT\")\n",
    "if not dagshub_token:\n",
    "    raise EnvironmentError(\"DAGSHUB_PAT environment variable is not set\")\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = dagshub_token\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = dagshub_token\n",
    "\n",
    "mlflow.set_tracking_uri(\n",
    "    \"https://dagshub.com/Pranay5519/yt-comment-sentiment-analysis-2.mlflow\"\n",
    ")\n",
    "# ---------------- ROOT PATH (MANUAL) ----------------\n",
    "ROOT_DIR = r\"D:\\yt-comment-sentiment-analysis2\"\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# logging configuration\n",
    "logger = logging.getLogger('model_building')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "if not logger.handlers:\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.DEBUG)\n",
    "\n",
    "    file_handler = logging.FileHandler('model_building_errors.log')\n",
    "    file_handler.setLevel(logging.ERROR)\n",
    "\n",
    "    formatter = logging.Formatter(\n",
    "        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    console_handler.setFormatter(formatter)\n",
    "    file_handler.setFormatter(formatter)\n",
    "\n",
    "    logger.addHandler(console_handler)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "\n",
    "def load_params(params_path: str) -> dict:\n",
    "    with open(params_path, 'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "\n",
    "\n",
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.fillna('', inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def apply_tfidf(\n",
    "    train_data: pd.DataFrame,\n",
    "    max_features: int,\n",
    "    ngram_range: tuple\n",
    ") -> tuple:\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=max_features,\n",
    "        ngram_range=ngram_range\n",
    "    )\n",
    "\n",
    "    X_train = train_data[\"clean_comment\"].values\n",
    "    y_train = train_data[\"category\"].values\n",
    "\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # save vectorizer at root\n",
    "    vectorizer_path = os.path.join(ROOT_DIR, \"tfidf_vectorizer.pkl\")\n",
    "    with open(vectorizer_path, \"wb\") as f:\n",
    "        pickle.dump(vectorizer, f)\n",
    "\n",
    "    logger.debug(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
    "    return X_train_tfidf, y_train\n",
    "\n",
    "\n",
    "def train_lgbm(X_train, y_train, learning_rate, max_depth, n_estimators):\n",
    "\n",
    "    model = lgb.LGBMClassifier(\n",
    "        objective=\"multiclass\",\n",
    "        num_class=3,\n",
    "        metric=\"multi_logloss\",\n",
    "        is_unbalance=True,\n",
    "        class_weight=\"balanced\",\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        n_estimators=n_estimators\n",
    "    )\n",
    "\n",
    "    mlflow.lightgbm.autolog(log_models=False)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # ðŸ”´ THIS LINE IS MANDATORY\n",
    "        mlflow.pyfunc.log_model(\n",
    "            python_model=model,\n",
    "            name=\"model\" , input_example=X_train   # MLflow 3.x\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, file_path: str) -> None:\n",
    "    with open(file_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    logger.debug(f\"Model saved at {file_path}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        params = load_params(\n",
    "            os.path.join(ROOT_DIR, \"params.yaml\")\n",
    "        )\n",
    "\n",
    "        mb_params = params[\"model_building\"]\n",
    "\n",
    "        train_data = load_data(\n",
    "            os.path.join(\n",
    "                ROOT_DIR,\n",
    "                \"data\",\n",
    "                \"interim\",\n",
    "                \"train_processed.csv\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        X_train_tfidf, y_train = apply_tfidf(\n",
    "            train_data,\n",
    "            mb_params[\"max_features\"],\n",
    "            tuple(mb_params[\"ngram_range\"])\n",
    "        )\n",
    "\n",
    "        model = train_lgbm(\n",
    "            X_train_tfidf,\n",
    "            y_train,\n",
    "            mb_params[\"learning_rate\"],\n",
    "            mb_params[\"max_depth\"],\n",
    "            mb_params[\"n_estimators\"]\n",
    "        )\n",
    "\n",
    "        save_model(\n",
    "            model,\n",
    "            os.path.join(ROOT_DIR, \"lgbm_model.pkl\")\n",
    "        )\n",
    "\n",
    "        logger.info(\"Model training completed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(\n",
    "            \"Model building pipeline failed\",\n",
    "            exc_info=True\n",
    "        )\n",
    "        raise\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
